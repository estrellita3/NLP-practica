{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP practica.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKJjfAOnZlpG"
      },
      "outputs": [],
      "source": [
        "subset \"5-core\" https://nijianmo.github.io/amazon/index.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('https://nijianmo.github.io/amazon/index.html')\n",
        "\n",
        "from utils import load_"
      ],
      "metadata": {
        "id": "bFy88QtWb3Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_path = '../../datasets'"
      ],
      "metadata": {
        "id": "8sKYFF7pb3Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_dict = load_cinema_reviews(datasets_path)"
      ],
      "metadata": {
        "id": "vlsSPk2Fb3WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = reviews_dict.get(10).get('review_text')\n",
        "print(review[:1000])"
      ],
      "metadata": {
        "id": "A52gnfXpb3Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = review.split('.')\n",
        "print(sentences[:5])"
      ],
      "metadata": {
        "id": "Wv6sUn2anPpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "pTWyntBOnPsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "wJDL4HLLnPu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, TreebankWordTokenizer, RegexpTokenizer"
      ],
      "metadata": {
        "id": "wuy2T6hhnPxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(review)"
      ],
      "metadata": {
        "id": "ZfOPDnqfnP0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in sentences:\n",
        "    for idx, word in enumerate(word_tokenize(sent)):\n",
        "        print('Palabra {0:10}{1:20}'.format(str(idx), word))"
      ],
      "metadata": {
        "id": "HFfOknuKb3bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = TreebankWordTokenizer()\n",
        "for sent in sentences:\n",
        "    for idx, word in enumerate(tokenizer.tokenize(sent)):\n",
        "        print('Palabra {0:10}{1:20}'.format(str(idx), word))"
      ],
      "metadata": {
        "id": "XljNA8eOb3eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = list()\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "for sent in sentences:\n",
        "    for idx, word in enumerate(tokenizer.tokenize(sent)):\n",
        "        print('Palabra {0:10}{1:20}'.format(str(idx), word))\n",
        "        words.append(word)"
      ],
      "metadata": {
        "id": "ahsfLwWrb3gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "yfsRQSU8b3jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def words(text): return re.findall(r'\\w+', text.lower())"
      ],
      "metadata": {
        "id": "KXHL6A9nqB18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(list(filter(None, reviews_list)))\n",
        "WORDS = Counter(words(text))"
      ],
      "metadata": {
        "id": "rH6_DcOvqB6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WORDS.most_common(100)"
      ],
      "metadata": {
        "id": "ohfgHuPSqB9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def P(word, N=sum(WORDS.values())): \n",
        "    \"Probability of `word`.\"\n",
        "    return WORDS[word] / N"
      ],
      "metadata": {
        "id": "BXlbgcEKqB_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correction(word): \n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)"
      ],
      "metadata": {
        "id": "5YJS_5gnt8MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])"
      ],
      "metadata": {
        "id": "QTNRWWEGt8O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def known(words): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)"
      ],
      "metadata": {
        "id": "-duQR7rPt8R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "^ -> start of string\n",
        "+ -> match 1 or more preceding regex\n",
        "[^@]+\n",
        "@[^@]+\n",
        "\\. -> '.'\n",
        "\"\"\"\n",
        "\n",
        "RE_EMAIL = re.compile('[^@]+@[^@]+\\.[^@]+')"
      ],
      "metadata": {
        "id": "XMpHTgOAt8UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emails_list = [\n",
        "    '@invalid@adress.com',\n",
        "    'correo_valido@gmail.com',\n",
        "    'notan@valido@gmail.com',\n",
        "    'si.valido.david@gmail.com',\n",
        "    'paginaweb.com',\n",
        "    'paginaweb.com@paginaweb.com'\n",
        "]\n",
        "for email in emails_list:\n",
        "    if RE_EMAIL.match(email):\n",
        "        print(test_pass(True, email))\n",
        "    else:\n",
        "        print(test_pass(False, email))"
      ],
      "metadata": {
        "id": "sPeS2szft8W9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "CnoNhcnjt8ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_nltk = text.lower().split()"
      ],
      "metadata": {
        "id": "GntaEYOSt8bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wf = Counter(words_nltk)"
      ],
      "metadata": {
        "id": "FZmn7KTPt8eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wf_most_common = wf.most_common(10)"
      ],
      "metadata": {
        "id": "93vhrw7lqCC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wf_most_common"
      ],
      "metadata": {
        "id": "QH1KN_rUqCFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [w[0] for w in wf_most_common]\n",
        "freqs = [w[1] for w in wf_most_common]"
      ],
      "metadata": {
        "id": "316im-PjqCIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ngrams\n",
        "from nltk.probability import FreqDist"
      ],
      "metadata": {
        "id": "aAkRUu4gqCKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigrams_ = list(ngrams(words_nltk, 2))\n",
        "trigrams_ = list(ngrams(words_nltk, 3))"
      ],
      "metadata": {
        "id": "df5SVQZRqCQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "RiD06UPiqCSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))"
      ],
      "metadata": {
        "id": "_ayyvlBJqCVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_word_cloud(text):\n",
        "    wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(' '.join(text))\n",
        "    plt.figure(figsize=(12,6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "JusebfwQwwUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from nltk.probability import FreqDist"
      ],
      "metadata": {
        "id": "hNXR1-xCwwf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fd = FreqDist(words)"
      ],
      "metadata": {
        "id": "58Bo6X6-wwkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fd"
      ],
      "metadata": {
        "id": "sdfMZ60awwoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = list()\n",
        "freqs = list()\n",
        "\n",
        "for rank, word in enumerate(fd):\n",
        "    ranks.append(rank+1)\n",
        "    freqs.append(fd[word])"
      ],
      "metadata": {
        "id": "i-BI22ZryJIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.loglog(ranks, freqs)\n",
        "plt.xlabel('Rank')\n",
        "plt.ylabel('Freq')\n",
        "plt.title('Log-Log rank-freq chart')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1p-DmcXSyJL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip3 install sklearn_crfsuite"
      ],
      "metadata": {
        "id": "0WPYt6QhyJOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import io\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics"
      ],
      "metadata": {
        "id": "9C347eYDyJRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_path = '../../'\n",
        "corpus_train_file = 'esp.train'\n",
        "corpus_test_file = 'esp.testa'\n",
        "corpus_val_file = 'esp.testb'"
      ],
      "metadata": {
        "id": "8GRfhKwmyJUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = load_data(os.path.join(datasets_path, corpus_train_file))\n",
        "df_test = load_data(os.path.join(datasets_path, corpus_test_file))\n",
        "df_val = load_data(os.path.join(datasets_path, corpus_val_file))"
      ],
      "metadata": {
        "id": "QYgC5sRqyJW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_train = get_sentences(df_train)\n",
        "sentences_test = get_sentences(df_test)\n",
        "sentences_val = get_sentences(df_val)"
      ],
      "metadata": {
        "id": "UsoCNb83yJZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_summary(df_train)"
      ],
      "metadata": {
        "id": "h4g8B3A50eWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_summary(df_test)"
      ],
      "metadata": {
        "id": "PmTICaV00eZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_train[3]"
      ],
      "metadata": {
        "id": "X0Z_c3E10ec8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_test[0]"
      ],
      "metadata": {
        "id": "5fTTpVon0efn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [sent2features(s) for s in sentences_train]\n",
        "y_train = [sent2labels(s) for s in sentences_train]\n",
        "\n",
        "X_test = [sent2features(s) for s in sentences_test]\n",
        "y_test = [sent2labels(s) for s in sentences_test]\n",
        "\n",
        "X_val = [sent2features(s) for s in sentences_val]\n",
        "y_val = [sent2labels(s) for s in sentences_val]"
      ],
      "metadata": {
        "id": "v5tJv9v10eiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OR3juE7N0ek3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lmCrBe7U0eoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZE5HfJtvqCX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LtnKxHVrb3l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SBv5wcLhb3oj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}